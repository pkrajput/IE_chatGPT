{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OcNuN6k7YBUW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import openai\n",
    "from PyPDF2 import PdfReader\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(pdf_pathfile, maxlen = None):\n",
    "    reader = PdfReader(pdf_pathfile)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text +=page.extract_text()\n",
    "    if maxlen:\n",
    "        if len(text) > maxlen:\n",
    "            text = text[:maxlen]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_pdf_chatgpt(url,savepath):\n",
    "    filename = url_to_filename(url, save_path, replace_signs=['https://www.','\\\\','/','+','*','?','=','%','#'])\n",
    "    if not os.path.exists(filename):\n",
    "        return np.nan\n",
    "    text = read_pdf(filename)\n",
    "    gpt_abstract = request_chatgpt(text)\n",
    "    return gpt_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_chatgpt(text, questions, prev_dict):\n",
    "    message = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"The previous info dict is %s\" %prev_dict},\n",
    "            {\"role\": \"assistant\", \"content\": \"I have full understanding of this chunk of article: %s\" %text},\n",
    "            {\"role\": \"user\", \"content\": 'Extract these relevant information in English and organise it as \"Python dict\" (IMPORTANT), value set as \"n/a\" if not applicable and append if multiple answers come out. Be particularly cautious on the n/a in the previous info dict and try your best to update precise info. Questions: %s' %questions }\n",
    "        ]\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo-16k\",messages=message,temperature=0)\n",
    "    extracted_info = response['choices'][0]['message']['content']\n",
    "    return response, extracted_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_text(text, questions, thegap=6000):\n",
    "    steps = []\n",
    "    prev_dict = {}\n",
    "    responses = []\n",
    "    for i in range(int(len(text)/thegap) + 1):\n",
    "        paper_chunk = text[i*thegap: (i+1)*thegap]\n",
    "        response, extracted_info = extract_info_chatgpt(paper_chunk, questions, prev_dict)\n",
    "        responses.append({'i':i, 'response':response, 'chunk':paper_chunk, 'extracted_info':extracted_info})\n",
    "        try:\n",
    "            prev_dict = eval(extracted_info)\n",
    "        except:\n",
    "            prev_dict = extracted_info\n",
    "        steps.append(prev_dict)\n",
    "    final_memory = steps[-1]\n",
    "    return final_memory, steps, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due Diligence Framework - Biotech.pdf \t cost 13.390319347381592 seconds\n",
      "Cost time 13.39067816734314 seconds\n"
     ]
    }
   ],
   "source": [
    "    pdf_path = '/home/prateek/sk_courses/IE_chatGPT/test_pdfs/'\n",
    "    files = [x for x in os.listdir(pdf_path)]\n",
    "\n",
    "    thegap = 8000\n",
    "    questions = ['What is the core technology proposed, including the type of therapy, its targets and its delivery vehicle?',\n",
    "                 'Would the proposed drug or tool+drug be significantly (10x) better than the current standard of care for their proposed diseases or for diseases that this would likely be used for?  Pull any safety and efficacy data for similar modalities and please try to contrast the advantages or disadvantages of this modality',\n",
    "                 'Is there evidence that this approach will work and what areas does the evidence not support? Is there evidence of a similar approval and for what component of the modality? What we need is information on: the drugs mechanism of action, its safety and efficacy profiles, the quality of clinical trials conducted, and all this for previous drugs and if they got approved',\n",
    "                 'How many companies like this exist both public and private competitors (please emphasize private) and what are their names and a short bio including who are their founders?',\n",
    "                 'List at least 10 different things this companys closest competitors listed above do and three bullets for each, have, or focus on that are unique to each one and can you mention a few words of how their drug design is unique too, team compositions, and others and clinical stage of their most relevant asset or latest clinical stage of their lead asset',\n",
    "                 'How is this company different from competitors (please focus on their technology and compare in one bullet the advantages of this technology to their competitors’ technologies and one bullet for the disadvantages of this technology to their competitors’ technologies)?  Next please summarise the most common advantages and disadvantages in bullets',\n",
    "                 'Does this company have the potential to hit $1B? What would be an IPO market cap estimated range for a similar company? What factors is this company strong or weak in - please use bullets',\n",
    "                 ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    file_steps = {}\n",
    "    for file in files:\n",
    "        text = read_pdf(pdf_path+file)\n",
    "        text = text.replace('\\n','').replace('  ',' ').replace('  ',' ').replace('  ',' ').replace('  ',' ').strip()\n",
    "        final_memory, steps, responses = extract_info_from_text(text, questions, thegap)\n",
    "        result_dict = {'final_memory':final_memory, 'steps':steps, 'responses':responses}\n",
    "        # Specify the file path where you want to save the JSON data\n",
    "#         file_path = '/home/prateek/sk_courses/IE_chatGPT/test_pdfs/result.json'\n",
    "\n",
    "        # Open the file in write mode and dump the dictionary contents as JSON\n",
    "#         with open(file_path, 'w') as json_file:\n",
    "#             json.dump(result_dict, json_file)\n",
    "#         file_steps[file] = result_dict\n",
    "        print(file, '\\t', f'cost {time.time() - start_time} seconds')\n",
    "    end_time = time.time()\n",
    "    print(f'Cost time {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in result_dict.items():\n",
    "    filename = f\"{key}.json\"  # Constructing the filename based on the key\n",
    "    \n",
    "    # Creating a dictionary with a single key-value pair\n",
    "    data = {key: value}\n",
    "\n",
    "    # Dumping the dictionary to a JSON file\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        # Create a PDF reader object\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        # Extract text from each page\n",
    "        long_text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            long_text += page.extract_text()\n",
    "    \n",
    "    return long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '/home/prateek/sk_courses/IE_chatGPT/test_pdfs/Pitch_to_test_on.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(pdf_path)\n",
    "final_memory, steps, responses = extract_info_from_text(text, questions, thegap)\n",
    "result_dict = {'final_memory':final_memory, 'steps':steps, 'responses':responses}\n",
    "\n",
    "for key, value in result_dict.items():\n",
    "    filename = f\"{key}.json\"  # Constructing the filename based on the key\n",
    "    \n",
    "    # Creating a dictionary with a single key-value pair\n",
    "    data = {key: value}\n",
    "\n",
    "    # Dumping the dictionary to a JSON file\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prateek/sk_courses/IE_chatGPT\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import openai\n",
    "import os\n",
    "\n",
    "pdf_summary_text = \"\"\n",
    "focus_of_paper = \"\"\n",
    "results_and_final_claim = \"\"\n",
    "soc_summary_text = \"\"\n",
    "\n",
    "pdf_file_path = \"./gunner/Prateek package/GeneEditingPapers/CRISPR-ph1.pdf\"\n",
    "pdf_file = open(pdf_file_path, 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "for page_num in range(len(pdf_reader.pages)):\n",
    "    page_text = pdf_reader.pages[page_num].extract_text().lower()\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"What was the focus of this page? {page_text}\"},\n",
    "        ],\n",
    "    )\n",
    "    focus_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    focus_of_paper += focus_response + \"\\n\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"What were the results and final claim of this page? {page_text}\"},\n",
    "        ],\n",
    "    )\n",
    "    results_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    results_and_final_claim += results_response + \"\\n\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize this page: {page_text}\"},\n",
    "        ],\n",
    "    )\n",
    "    page_summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    pdf_summary_text += page_summary + \"\\n\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"What is the standard of care for this disease? Pull the safety and efficacy data and summarize: {page_text}\"},\n",
    "    ],\n",
    "    )\n",
    "    soc_summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    soc_summary_text += soc_summary + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], \"_summary.txt\")\n",
    "with open(pdf_summary_file, \"w+\") as file:\n",
    "    file.write(\"Focus of the Paper:\\n\")\n",
    "    file.write(focus_of_paper)\n",
    "    file.write(\"\\nResults and Final Claim:\\n\")\n",
    "    file.write(results_and_final_claim)\n",
    "    file.write(\"\\nSummary:\\n\")\n",
    "    file.write(pdf_summary_text)\n",
    "    file.write(\"\\nSafety:\\n\")\n",
    "    file.write(soc_summary_text)\n",
    "\n",
    "pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {\"focus\": focus_of_paper, 'claim': results_and_final_claim, 'summary': pdf_summary_text, 'soc': soc_summary_text}\n",
    "\n",
    "answer_dict = {}\n",
    "\n",
    "for key, value in query_dict.items():\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"What is the standard of care for this disease? Pull the safety and efficacy data and summarize? {value}\"}\n",
    "        ]\n",
    "    )\n",
    "    answer_dict[key] = response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'focus': 'Based on the provided descriptions, the standard of care for transfusion-dependent β-thalassemia (TDT) and sickle cell disease (SCD) involves transfusion support and symptomatic management. However, the focus of these pages is on a study involving CRISPR-Cas9 gene editing with the aim of improving clinical outcomes for patients with TDT and SCD.\\n\\nThe study aimed to evaluate the effectiveness of editing the bcl11a erythroid-specific enhancer using CRISPR-Cas9 in CD34+ hematopoietic stem and progenitor cells. The results showed successful editing of the alleles at this locus, leading to increases in fetal hemoglobin, transfusion independence, and improvement in disease symptoms in the patients.\\n\\nFurther details provided in some of the pages include the collection of CD34+ hematopoietic stem and progenitor cells from patients, the editing of these cells with CRISPR-Cas9, and the subsequent infusion of the edited cells into the patients. The assessment of clinical outcomes, including engraftment, levels of edited alleles, changes in hemoglobin levels, and improvements in disease symptoms, are also mentioned.\\n\\nIn terms of safety and efficacy data, the pages mention successful gene editing, high levels of fetal hemoglobin expression, and improved clinical outcomes. However, adverse events experienced by the study patients are also discussed.\\n\\nIt is important to note that the provided information is a summary of the descriptions and does not encompass the entirety of the safety and efficacy data. It would be necessary to access the specific studies or articles referenced in order to obtain more comprehensive information.',\n",
       " 'claim': \"Apologies, but as a language model AI, I don't have access to current studies or the ability to browse the internet. I can only provide general information and answer questions based on what I have been trained on. For specific information, it would be best to consult the original article or study mentioned in the text.\",\n",
       " 'summary': 'The standard of care for transfusion-dependent β-thalassemia (TDT) and sickle cell disease (SCD) currently involves supportive treatments such as blood transfusions, iron chelation therapy, and hydroxyurea. \\n\\nThe research study published in The New England Journal of Medicine investigated the use of CRISPR-Cas9 gene editing to modify the BCL11A gene in hematopoietic stem cells obtained from healthy donors. Two patients, one with TDT and the other with SCD, received these edited cells after myeloablation. \\n\\nOver a year later, both patients showed high levels of gene editing, increased fetal hemoglobin levels, transfusion independence, and improvements in disease symptoms. However, the study also reported adverse events in the patients, including pneumonia, liver disease, and sepsis, which were all resolved with treatment.\\n\\nThe study was sponsored by Crispr Therapeutics and Vertex Pharmaceuticals and has shown promising results in terms of increasing fetal hemoglobin levels and reducing the need for transfusions in patients with TDT and SCD. However, further research is needed to assess the long-term safety and efficacy of this gene editing therapy.',\n",
       " 'soc': 'I apologize for any confusion, but based on the information provided, I cannot pull safety and efficacy data or summarize the standard of care for the specific disease or treatment mentioned. Please provide more specific information or clarify your question, and I will do my best to assist you.'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script to dump directory to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gunner/Prateek package/GeneEditingPapers/4dmt-interim data.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/nejmoa2107454.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/10.1038@s41591-018-0327-9.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/CRISPR-ph1.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/first-systemic-crispr-agent-in-humans-2020.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/gene-editing approaches.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/fmed-08-750586.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/sangamoPh1.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/viral_deliver.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/eye-gene-therapies.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import openai\n",
    "import csv\n",
    "\n",
    "directory = \"./gunner/Prateek package/GeneEditingPapers/\"  \n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file = './gunner/Prateek package/GeneEditingPapers/results.csv'\n",
    "\n",
    "is_first_step = True\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "# Print the file paths\n",
    "for file_path in file_paths:\n",
    "    print(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file in write mode and write the header row\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(answer_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['focus', 'claim', 'summary', 'paper'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gunner/Prateek package/GeneEditingPapers/4dmt-interim data.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/nejmoa2107454.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/10.1038@s41591-018-0327-9.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/CRISPR-ph1.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/first-systemic-crispr-agent-in-humans-2020.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/gene-editing approaches.pdf\n",
      "./gunner/Prateek package/GeneEditingPapers/fmed-08-750586.pdf\n"
     ]
    },
    {
     "ename": "ServiceUnavailableError",
     "evalue": "The server is overloaded or not ready yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceUnavailableError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m focus_response \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     24\u001b[0m focus_of_paper \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m focus_response \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful research assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat were the results and final claim of this page? \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpage_text\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m results_response \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     34\u001b[0m results_and_final_claim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m results_response \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/sk_courses/env/lib/python3.8/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/sk_courses/env/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/sk_courses/env/lib/python3.8/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/sk_courses/env/lib/python3.8/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/sk_courses/env/lib/python3.8/site-packages/openai/api_requestor.py:743\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OpenAIResponse(\u001b[38;5;28;01mNone\u001b[39;00m, rheaders)\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m503\u001b[39m:\n\u001b[0;32m--> 743\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mServiceUnavailableError(\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe server is overloaded or not ready yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    745\u001b[0m         rbody,\n\u001b[1;32m    746\u001b[0m         rcode,\n\u001b[1;32m    747\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrheaders,\n\u001b[1;32m    748\u001b[0m     )\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m rheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mServiceUnavailableError\u001b[0m: The server is overloaded or not ready yet."
     ]
    }
   ],
   "source": [
    "for path in file_paths:\n",
    "    \n",
    "    print(path)\n",
    "    \n",
    "    pdf_summary_text = \"\"\n",
    "    focus_of_paper = \"\"\n",
    "    results_and_final_claim = \"\"\n",
    "\n",
    "    pdf_file_path = path\n",
    "    pdf_file = open(pdf_file_path, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page_text = pdf_reader.pages[page_num].extract_text().lower()\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"What was the focus of this page? {page_text}\"},\n",
    "            ],\n",
    "        )\n",
    "        focus_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        focus_of_paper += focus_response + \"\\n\"\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"What were the results and final claim of this page? {page_text}\"},\n",
    "            ],\n",
    "        )\n",
    "        results_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        results_and_final_claim += results_response + \"\\n\"\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Summarize this page: {page_text}\"},\n",
    "            ],\n",
    "        )\n",
    "        page_summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        pdf_summary_text += page_summary + \"\\n\"\n",
    "        \n",
    "    pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], \"_summary.txt\")\n",
    "    with open(pdf_summary_file, \"w+\") as file:\n",
    "        file.write(\"Focus of the Paper:\\n\")\n",
    "        file.write(focus_of_paper)\n",
    "        file.write(\"\\nResults and Final Claim:\\n\")\n",
    "        file.write(results_and_final_claim)\n",
    "        file.write(\"\\nSummary:\\n\")\n",
    "        file.write(pdf_summary_text)\n",
    "\n",
    "    pdf_file.close()\n",
    "\n",
    "\n",
    "\n",
    "    query_dict = {\"focus\": focus_of_paper, 'claim': results_and_final_claim, 'summary': pdf_summary_text}\n",
    "\n",
    "    answer_dict = {}\n",
    "\n",
    "    for key, value in query_dict.items():\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"What was the summary of this text? {value}\"}\n",
    "            ]\n",
    "        )\n",
    "        answer_dict[key] = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    file_name = os.path.basename(path)\n",
    "    file_name = os.path.splitext(file_name)[0]\n",
    "    answer_dict['paper'] = file_name\n",
    "    \n",
    "    \n",
    "    # Open the CSV file in append mode and write the dictionary values\n",
    "    with open(csv_file, 'a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=answer_dict.keys())\n",
    "\n",
    "        # Write the values as a new row\n",
    "        writer.writerow(answer_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def convert_to_bullet_points(paragraph):\n",
    "    # Split the paragraph into sentences\n",
    "    sentences = paragraph.split('. ')\n",
    "    \n",
    "    # Add bullet points to each sentence\n",
    "    bullet_points = ['\\u2022 ' + sentence for sentence in sentences]\n",
    "    \n",
    "    # Join the bullet points to form a new paragraph\n",
    "    new_paragraph = '\\n'.join(bullet_points)\n",
    "    \n",
    "    return new_paragraph\n",
    "\n",
    "def convert_csv_to_bullet_points(input_file, output_file):\n",
    "    with open(input_file, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        headers = next(reader)  # Read the header row\n",
    "        \n",
    "        # Create a dictionary to store the modified data\n",
    "        modified_data = {header: [] for header in headers}\n",
    "        \n",
    "        for row in reader:\n",
    "            for i, value in enumerate(row):\n",
    "                modified_value = convert_to_bullet_points(value)\n",
    "                modified_data[headers[i]].append(modified_value)\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(headers)  # Write the header row\n",
    "        \n",
    "        # Write the modified data\n",
    "        for i in range(len(modified_data[headers[0]])):\n",
    "            row = [modified_data[header][i] for header in headers]\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Example usage\n",
    "input_file = './gunner/Prateek package/GeneEditingPapers/results.csv'\n",
    "output_file = './gunner/Prateek package/GeneEditingPapers/output.csv'\n",
    "\n",
    "convert_csv_to_bullet_points(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
